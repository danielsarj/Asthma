katie_weights <- katie_weights %>% select(-V1)
# make Katie's metadata
katie_meta <- fread('/Volumes/daniel/katieData/ATACseq_metadata.txt')
katie_meta <- katie_meta[which(!katie_meta$Condition=='Mock'),]
katie_meta <- katie_meta[!grepl('EU122', katie_meta$Genotyping_ID),]
## factorize certain columns from meta data
katie_meta$Batch <- as.factor(katie_meta$Batch)
katie_meta$Genotyping_ID <- as.factor(katie_meta$Genotyping_ID)
katie_meta$Condition <- factor(katie_meta$Condition, levels=c('NI','Flu'))
# run differential analysis
katie_design <- model.matrix(~0+Genotyping_ID+Condition, data=katie_meta)
katie_design <- katie_design[,colSums(katie_design!=0)>0]
katie_fit <- lmFit(katie_count, design=katie_design, weights=katie_weights) %>% eBayes()
# get results
katie_results <- topTable(katie_fit, coef=ncol(katie_fit), number=Inf)
###
# get predicted count matrix
# set vectors of indv IDs, the conditions, and different model folds
ids <- c('AF04','AF06','AF08','AF10','AF12','AF14','AF16','AF18','AF20','AF22',
'AF24','AF26','AF28','AF30','AF34','AF36','AF38','EU03','EU05',
'EU07','EU09','EU13','EU15','EU17','EU19','EU21','EU25','EU27',
'EU29','EU33','EU37','EU39','EU41','EU43','EU47')
conditions <- c('NI', 'Flu')
folds <- c(0,1,2,3,4)
# for every condition and indv
for (co in conditions){
for (i in ids){
print(i)
# read the result of all folds and combine them
for (f in folds){
if (f==0){
prediction <- fread('chrombpnet_nobias_model/'%&%co%&%'_fold0_'%&%i%&%'_bwavg.txt.gz') %>% select(V1,V4)
} else {
t <- fread('chrombpnet_nobias_model/'%&%co%&%'_fold'%&%f%&%'_'%&%i%&%'_bwavg.txt.gz') %>% select(V1,V4)
prediction <- inner_join(prediction, t, by=c('V1'))
}
}
# compute average predicted accessibility across folds
averages <- rowMeans(prediction[,(ncol(prediction)-4):ncol(prediction)])
prediction <- prediction %>% mutate(!!c(i %&%'_'%&% co):=as.integer(round(averages))) %>% select(V1, c(i %&%'_'%&% co))
# append to final data frame
if (exists('predicted_count')){
predicted_count <- inner_join(predicted_count, prediction, by=c('V1'))
} else { predicted_count <- prediction}
}
}
predicted_count <- predicted_count %>% as.data.frame()
row.names(predicted_count) <- predicted_count$V1
predicted_count <- predicted_count %>% select(-V1) %>% drop_na() %>% DGEList() %>%
calcNormFactors()
# predicted voom
predicted_groups <- c(rep('NI', length(ids)), rep('Flu', length(ids))) %>%
factor(levels=c('NI','Flu'))
predicted_ids <- rep(ids, length(conditions)) %>% as.factor()
predicted_design <- model.matrix(~0+predicted_ids+predicted_groups)
predicted_voom <- voom(predicted_count, predicted_design, plot=T)
predicted_fit <-  lmFit(predicted_voom) %>% eBayes()
# get results
predicted_results <- topTable(predicted_fit, coef=ncol(predicted_fit), number=Inf)
###
# compare katie's results to predicted results
# get shared peaks
katie_results_df <- katie_results %>% as.data.frame() %>% rownames_to_column('peakID')
predicted_results_df <- predicted_results %>% as.data.frame() %>% rownames_to_column('peakID')
combined_dfs <- inner_join(katie_results_df, predicted_results_df, by=c('peakID'))
common_peaks <- combined_dfs %>% select(peakID) %>% pull()
View(combined_dfs)
ggplot(combined_dfs) + geom_point(aes(x=logFC.x, y=logFC.y)) +
xlab('Measured DA logFC') + ylab('Predicted DA logFC') + geom_abline(slope=1, color='red') +
stat_smooth(aes(x=logFC.x, y=logFC.y), method='lm', geom='smooth', formula=y~x) + theme_bw()
# combine results and save it
katie_results_df <- katie_results_df %>% mutate(data='real')
predicted_results_df <- predicted_results_df %>% mutate(data='pred')
combined_DA <- rbind(katie_results_df, predicted_results_df)
View(combined_DA)
fwrite(combined_DA, 'combinedDApeaks_dataframe.txt', sep=' ')
# filter out non-shared peaks
katie_results_df <- katie_results_df %>% filter(peakID %in% common_peaks)
predicted_results_df <- predicted_results_df %>% filter(peakID %in% common_peaks)
combined_DA <- rbind(katie_results_df, predicted_results_df)
fwrite(combined_DA, 'commonDApeaks_dataframe.txt', sep=' ')
# make volcano plots of DA peaks
ggplot(combined_DA) + geom_point(aes(x=logFC, y=-log10(adj.P.Val), color=sig)) +
facet_wrap(~data) + theme_bw()
# make volcano plots of DA peaks
ggplot(combined_DA) + geom_point(aes(x=logFC, y=-log10(adj.P.Val))) +
facet_wrap(~data) + theme_bw()
ggsave('commonDApeaks_volcanoplots.pdf', height=5, width=8)
katie_results_df <- katie_results %>% as.data.frame() %>% rownames_to_column('peakID')
predicted_results_df <- predicted_results %>% as.data.frame() %>% rownames_to_column('peakID')
combined_dfs <- inner_join(katie_results_df, predicted_results_df, by=c('peakID'))
common_peaks <- combined_dfs %>% select(peakID) %>% pull()
# combine results and save it
katie_results_df <- katie_results_df %>% mutate(data='real')
predicted_results_df <- predicted_results_df %>% mutate(data='pred')
combined_DA <- rbind(katie_results_df, predicted_results_df)
fwrite(combined_DA, 'combinedDApeaks_dataframe.txt', sep=' ')
# make volcano plots of DA peaks
ggplot(combined_DA) + geom_point(aes(x=logFC, y=-log10(adj.P.Val))) +
facet_wrap(~data) + theme_bw()
View(combined_DA)
View(katie_results_df)
nrow(katie_results_df) + nrow(predicted_results_df)
ggsave('combinedDApeaks_volcanoplots.pdf', height=5, width=8)
# filter out non-shared peaks
katie_results_df <- katie_results_df %>% filter(peakID %in% common_peaks)
predicted_results_df <- predicted_results_df %>% filter(peakID %in% common_peaks)
combined_DA <- rbind(katie_results_df, predicted_results_df)
fwrite(combined_DA, 'commonDApeaks_dataframe.txt', sep=' ')
# make volcano plots of DA peaks
ggplot(combined_DA) + geom_point(aes(x=logFC, y=-log10(adj.P.Val))) +
facet_wrap(~data) + theme_bw()
ggsave('commonDApeaks_volcanoplots.pdf', height=5, width=8)
# load libraries and databases
library(tidyverse)
library(data.table)
library(GenomicRanges)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
library(ChIPseeker)
library(ReactomePA)
library(org.Hs.eg.db)
library(clusterProfiler)
library(fgsea)
library(msigdbr)
"%&%" <- function(a,b) paste(a,b, sep = "")
txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene
DAfile <- fread('combinedDApeaks_dataframe.txt')
# make model-specific GRange objects
pred_DA <- DAfile %>% filter(data=='pred') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':') %>% makeGRangesFromDataFrame()
real_DA <- DAfile %>% filter(data=='real') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':') %>% makeGRangesFromDataFrame()
View(DAfile)
View(pred_DA)
real_DA <- DAfile %>% filter(data=='real') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':') #%>% makeGRangesFromDataFrame()
View(real_DA)
table(read_DA$chr)
table(real_DA$chr)
table(real_DA$start)
real_DA <- DAfile %>% filter(data=='real') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':') %>% filter(is.numeric(start)==T,
is.numeric(end)==T) %>%
makeGRangesFromDataFrame()
View(real_DA)
real_DA <- DAfile %>% filter(data=='real') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':') %>%
makeGRangesFromDataFrame()
real_DA <- DAfile %>% filter(data=='real') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':')
real_DA$start <- as.numeric(real_DA$start)
real_DA$end <- as.numeric(real_DA$end)
real_DA <- real_DA %>% drop_na() %>% makeGRangesFromDataFrame()
?annotatePeak
# annotate peaks
pred_annot <- annotatePeak(pred_DA, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb='org.Hs.eg.db') %>%
as.data.frame() #%>% mutate(peakID=seqnames%&%':'%&%start%&%':'%&%end) %>%
View(pred_annot)
# annotate peaks
pred_annot <- annotatePeak(pred_DA, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb='org.Hs.eg.db') %>%
as.data.frame() %>% mutate(peakID=seqnames%&%':'%&%start%&%':'%&%end) %>%
group_by(SYMBOL) %>% slice(which.min(abs(distanceToTSS)))
View(pred_annot)
?enrichGO
DAfile <- fread('combinedDApeaks_dataframe.txt') %>% mutate(sig=adj.P.Val<0.05 & abs(logFC)>1)
# make model-specific GRange objects for sig DA peaks
pred_DA <- DAfile %>% filter(data=='pred', sig==T) %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':') %>% makeGRangesFromDataFrame()
real_DA <- DAfile %>% filter(data=='real', sig==T) %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':')
real_DA$start <- as.numeric(real_DA$start)
real_DA$end <- as.numeric(real_DA$end)
real_DA <- real_DA %>% drop_na() %>% makeGRangesFromDataFrame()
# annotate peaks
pred_annot <- annotatePeak(pred_DA, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb='org.Hs.eg.db') %>%
as.data.frame() %>% mutate(peakID=seqnames%&%':'%&%start%&%':'%&%end) %>%
group_by(SYMBOL) %>% slice(which.min(abs(distanceToTSS)))
real_annot <- annotatePeak(real_DA, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb='org.Hs.eg.db') %>%
as.data.frame() %>% mutate(peakID=seqnames%&%':'%&%start%&%':'%&%end) %>%
group_by(SYMBOL) %>% slice(which.min(abs(distanceToTSS)))
# get info about peak subsets (real/pred only; intersection)
pred_peaks <- DAfile %>% filter(data=='pred', sig==TRUE) %>% dplyr::select(peakID) %>% pull()
real_peaks <- DAfile %>% filter(data=='real', sig==TRUE) %>% dplyr::select(peakID) %>% pull()
pred.only_annot <- pred_annot %>% filter(peakID %in% pred_peaks & !(peakID %in% real_peaks))
real.only_annot <- real_annot %>% filter(peakID %in% real_peaks & !(peakID %in% pred_peaks))
pred.real_annot <- pred_annot %>% filter(peakID %in% pred_peaks & peakID %in% real_peaks)
# quick summary
pred.only_annot$annotation <- gsub("\\(.*?\\)", "", pred.only_annot$annotation)
pred.only_annot$annotation <- trimws(pred.only_annot$annotation)
pred.only_summary <- pred.only_annot %>% group_by(annotation) %>%
summarise(count=n(), perc=(n()/nrow(pred.only_annot))*100) %>%
mutate(DApeak='pred')
real.only_annot$annotation <- gsub("\\(.*?\\)", "", real.only_annot$annotation)
real.only_annot$annotation <- trimws(real.only_annot$annotation)
real.only_summary <- real.only_annot %>% group_by(annotation) %>%
summarise(count=n(), perc=(n()/nrow(real.only_annot))*100) %>%
mutate(DApeak='real')
pred.real_annot$annotation <- gsub("\\(.*?\\)", "", pred.real_annot$annotation)
pred.real_annot$annotation <- trimws(pred.real_annot$annotation)
pred.real_summary <- pred.real_annot %>% group_by(annotation) %>%
summarise(count=n(), perc=(n()/nrow(pred.real_annot))*100)  %>%
mutate(DApeak='pred&real')
# barplot idk
merged_summary <- rbind(pred.only_summary, real.only_summary, pred.real_summary)
ggplot(merged_summary) + geom_col(aes(x=annotation, y=perc, fill=DApeak), position='dodge') +
theme_bw() + coord_flip()
# enriched GO terms
pred.GO <- enrichGO(pred.only_annot$geneId, org.Hs.eg.db, ont='MF') %>%
as.data.frame() %>% mutate(DApeak='pred')
real.GO <- enrichGO(real.only_annot$geneId, org.Hs.eg.db, ont='MF') %>%
as.data.frame() %>% mutate(DApeak='real')
pred.real.GO <- enrichGO(pred.real_annot$geneId, org.Hs.eg.db, ont='MF') %>%
as.data.frame() %>% mutate(DApeak='pred&real')
# join dfs
jointGOs <- rbind(pred.GO, real.GO, pred.real.GO) %>% select(Description, FoldEnrichment, p.adjust, DApeak)
ggplot(jointGOs) + geom_point(aes(x=DApeak, y=Description, color=FoldEnrichment, size=p.adjust)) +
theme_bw() + scale_size(transform='reverse')
View(real.only_annot)
View(pred_annot)
View(real_annot)
pred.real_annot <- intersect(pred_peaks, real_peaks)
pred.real_annot <- rbind(pred_annot, real_annot) %>% filter(peakID %in% intersect(pred_peaks, real_peaks))
View(real.only_annot)
# GSEA
# make model-specific GRange objects for all peaks
pred_DA <- DAfile %>% filter(data=='pred') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':') %>% makeGRangesFromDataFrame()
real_DA <- DAfile %>% filter(data=='real') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':') %>% makeGRangesFromDataFrame()
# GSEA
# make model-specific GRange objects for all peaks
pred_DA <- DAfile %>% filter(data=='pred') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':') %>% makeGRangesFromDataFrame()
real_DA <- DAfile %>% filter(data=='real') %>% dplyr::select(peakID) %>%
separate(peakID, into=c('chr', 'start', 'end'), sep=':')
real_DA$start <- as.numeric(real_DA$start)
real_DA$end <- as.numeric(real_DA$end)
real_DA <- real_DA %>% drop_na() %>% makeGRangesFromDataFrame()
# annotate peaks
pred_annot <- annotatePeak(pred_DA, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb='org.Hs.eg.db') %>%
as.data.frame() %>% mutate(peakID=seqnames%&%':'%&%start%&%':'%&%end) %>%
group_by(SYMBOL) %>% slice(which.min(abs(distanceToTSS)))
real_annot <- annotatePeak(real_DA, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb='org.Hs.eg.db') %>%
as.data.frame() %>% mutate(peakID=seqnames%&%':'%&%start%&%':'%&%end) %>%
group_by(SYMBOL) %>% slice(which.min(abs(distanceToTSS)))
# perform gsea
pred_pathways <- msigdbr(species='Homo sapiens', category='H') %>%
split(x=.$gene_symbol, f=.$gs_name)
pred_gsea <- DAfile %>% filter(data=='pred') %>%
right_join(pred_annot) %>% arrange(logFC)
pred_ranks <- pred_gsea %>% select(geneId, logFC)
pred_ranks <- setNames(pred_ranks$logFC, pred_ranks$geneId)
pred_gsea <- fgsea(pathways=pred_pathways, stats=pred_ranks, minSize=15, maxSize=500)
pred.topPathwaysUp <- pred_gsea[ES > 0][head(order(pval), n=10), pathway]
pred.topPathwaysDown <- pred_gsea[ES < 0][head(order(pval), n=10), pathway]
pred.topPathways <- c(pred.topPathwaysUp, rev(pred.topPathwaysDown))
plotGseaTable(pred_pathways[pred.topPathways], pred_ranks, pred_gsea, gseaParam=0.5)
View(pred_pathways)
pred_gsea <- DAfile %>% filter(data=='pred') %>%
right_join(pred_annot) %>% arrange(logFC)
View(pred_gsea)
pred_ranks <- pred_gsea %>% select(geneId, logFC)
pred_gsea <- DAfile %>% filter(data=='pred') %>%
right_join(pred_annot) %>% arrange(logFC)
pred_gsea <- DAfile %>% filter(data=='pred') %>%
right_join(pred_annot) %>% arrange(t)
pred_ranks <- pred_gsea %>% select(geneId, t)
pred_ranks <- setNames(pred_ranks$t, pred_ranks$geneId)
pred_ranks
pred_gsea <- DAfile %>% filter(data=='pred') %>%
right_join(pred_annot) %>% arrange(t)
pred_ranks <- pred_gsea %>% select(SYMBOL, t)
pred_ranks <- setNames(pred_ranks$t, pred_ranks$SYMBOL)
pred_gsea <- fgsea(pathways=pred_pathways, stats=pred_ranks, minSize=15, maxSize=500)
pred_ranks
pred_gsea <- DAfile %>% filter(data=='pred') %>%
right_join(pred_annot) %>% arrange(t)
pred_ranks <- pred_gsea %>% select(SYMBOL, t)
pred_ranks <- setNames(pred_ranks$t, pred_ranks$SYMBOL) %>% drop_na()
pred_gsea <- DAfile %>% filter(data=='pred') %>%
right_join(pred_annot) %>% arrange(t)
pred_ranks <- pred_gsea %>% select(SYMBOL, t) %>% drop_na()
pred_ranks <- setNames(pred_ranks$t, pred_ranks$SYMBOL)
pred_gsea <- fgsea(pathways=pred_pathways, stats=pred_ranks, minSize=15, maxSize=500)
pred.topPathwaysUp <- pred_gsea[ES > 0][head(order(pval), n=10), pathway]
pred.topPathwaysDown <- pred_gsea[ES < 0][head(order(pval), n=10), pathway]
pred.topPathways <- c(pred.topPathwaysUp, rev(pred.topPathwaysDown))
plotGseaTable(pred_pathways[pred.topPathways], pred_ranks, pred_gsea, gseaParam=0.5)
real_gsea <- DAfile %>% filter(data=='real') %>%
right_join(real_annot) %>% arrange(t)
real_ranks <- real_gsea %>% select(SYMBOL, t) %>% drop_na()
real_pathways <- reactomePathways(real_ranks$SYMBOL)
# perform gsea
pred_pathways <- msigdbr(species='Homo sapiens', category='H') %>%
split(x=.$gene_symbol, f=.$gs_name)
pred_gsea <- DAfile %>% filter(data=='pred') %>%
right_join(pred_annot) %>% arrange(t)
pred_ranks <- pred_gsea %>% select(SYMBOL, t) %>% drop_na()
pred_ranks <- setNames(pred_ranks$t, pred_ranks$SYMBOL)
pred_gsea <- fgsea(pathways=pred_pathways, stats=pred_ranks, minSize=15, maxSize=500)
pred.topPathwaysUp <- pred_gsea[ES > 0][head(order(pval), n=10), pathway]
pred.topPathwaysDown <- pred_gsea[ES < 0][head(order(pval), n=10), pathway]
pred.topPathways <- c(pred.topPathwaysUp, rev(pred.topPathwaysDown))
plotGseaTable(pred_pathways[pred.topPathways], pred_ranks, pred_gsea, gseaParam=0.5)
real_gsea <- DAfile %>% filter(data=='real') %>%
right_join(real_annot) %>% arrange(t)
real_ranks <- real_gsea %>% select(SYMBOL, t) %>% drop_na()
real_ranks <- setNames(real_ranks$T, real_ranks$SYMBOL)
real_gsea <- DAfile %>% filter(data=='real') %>%
right_join(real_annot) %>% arrange(t)
real_ranks <- real_gsea %>% select(SYMBOL, t) %>% drop_na()
real_ranks <- setNames(real_ranks$t, real_ranks$SYMBOL)
real_gsea <- fgsea(pathways=pathways, stats=real_ranks, minSize=15, maxSize=500)
# perform gsea
pathways <- msigdbr(species='Homo sapiens', category='H') %>%
split(x=.$gene_symbol, f=.$gs_name)
real_gsea <- fgsea(pathways=pathways, stats=real_ranks, minSize=15, maxSize=500)
real.topPathwaysUp <- real_gsea[ES > 0][head(order(pval), n=10), pathway]
real.topPathwaysDown <- real_gsea[ES < 0][head(order(pval), n=10), pathway]
real.topPathways <- c(real.topPathwaysUp, rev(real.topPathwaysDown))
plotGseaTable(real_pathways[real.topPathways], real_ranks, real_gsea, gseaParam=0.5)
plotGseaTable(pathways[real.topPathways], real_ranks, real_gsea, gseaParam=0.5)
joint_gsea <- rbind(mutate(pred_gsea, data='pred'), mutate(real_gsea, data='real'))
View(joint_gsea)
fwrite(joint_gsea, 'GSEA_joint.df.txt', sep=' ')
sig_joint_gsea <- joint_gsea %>% filter(padj < 0.05)
View(sig_joint_gsea)
View(real_gsea)
library(rhdf5)
"%&%" <- function(a,b) paste(a,b, sep = "")
setwd("/Volumes/daniel/deeplearn_pred/DIY/contribution_scores")
conditions <- c('NI', 'Flu')
sets <- c('counts', 'profile')
dset <- 'counts'
cond <- 'Flu'
# list all .h5 files in the folder
h5_files <- list.files(getwd(),
pattern='^'%&%cond%&%'.*\\.'%&%dset%&%'_scores\\.h5$',
full.names=T)
h5_files
# initialize a list to store datasets
datasets <- list()
# look for the specific groups and datasets
target_groups <- c("/projected_shap", "/raw", "/shap")
for (file in h5_files){
h5_structure <- h5ls(file)
for (group in target_groups){
# construct the full path to the dataset
full_key <- c(group%&%"/seq")
if (full_key %in% h5_structure$fullname){
# read the dataset
data <- h5read(file, full_key)
# add or initialize the dataset in the list
if (!is.null(datasets[[full_key]])) {
datasets[[full_key]] <- datasets[[full_key]] + data
} else {
datasets[[full_key]] <- data
}
}
}
}
View(h5_structure)
datasets
# average the accumulated datasets
file_count <- length(h5_files)
for (key in names(datasets)){
datasets[[key]] <- datasets[[key]] / file_count
}
# save new file
output_file <- getwd()%&%'/'%&%cond%&%'_avg_'%&%dset%&%'_scores.h5'
if (file.exists(output_file)){
file.remove(output_file)
}
for (key in names(datasets)){
chunk_dims <- c(min(nrow(datasets[[key]]), 100), ncol(datasets[[key]]),
if (length(dim(datasets[[key]])) > 2) min(dim(datasets[[key]])[3], 100) else NULL)
h5createFile(output_file)
h5createDataset(output_file, dataset=key, dims=dim(datasets[[key]]),
chunk=chunk_dims)
h5write(datasets[[key]], output_file, key)
}
cat('Average '%&%dset%&%' for '%&%cond%&%' saved.')
for (file in h5_files){
h5_structure <- h5ls(file)
for (group in target_groups){
# construct the full path to the dataset
full_key <- c(group%&%"/seq")
if (full_key %in% h5_structure$fullname){
# read the dataset
data <- h5read(file, full_key)
# add or initialize the dataset in the list
if (!is.null(datasets[[full_key]])) {
datasets[[full_key]] <- datasets[[full_key]] + data
} else {
datasets[[full_key]] <- data
}
}
}
}
file
h5_structure
h5ls(file)
# read the dataset
data <- h5read(file, full_key)
h5_structure$fullname
# add or initialize the dataset in the list
if (!is.null(datasets[[full_key]])) {
datasets[[full_key]] <- datasets[[full_key]] + data
} else {
datasets[[full_key]] <- data
}
View(datasets)
conditions <- c('NI', 'Flu')
sets <- c('counts', 'profile')
for (dset in sets){
for (cond in conditions){
dset <- 'counts'
}}
dset <- 'counts'
cond <- 'NI'
# list all .h5 files in the folder
h5_files <- list.files(getwd(),
pattern='^'%&%cond%&%'.*\\.'%&%dset%&%'_scores\\.h5$',
full.names=T)
"%&%" <- function(a,b) paste(a,b, sep = "")
# list all .h5 files in the folder
h5_files <- list.files(getwd(),
pattern='^'%&%cond%&%'.*\\.'%&%dset%&%'_scores\\.h5$',
full.names=T)
# initialize a list to store datasets
datasets <- list()
# look for the specific groups and datasets
target_groups <- c("/projected_shap", "/raw", "/shap")
for (file in h5_files){
h5_structure <- h5ls(file)
for (group in target_groups){
# construct the full path to the dataset
full_key <- c(group%&%"/seq")
# read the dataset
data <- h5read(file, full_key)
# add or initialize the dataset in the list
if (!is.null(datasets[[full_key]])) {
datasets[[full_key]] <- datasets[[full_key]] + data
} else {
datasets[[full_key]] <- data
}
}
}
rm(datasets)
?h5write
?h5createDataset
# list all .h5 files in the folder
h5_files <- list.files(getwd(),
pattern='^'%&%cond%&%'.*\\.'%&%dset%&%'_scores\\.h5$',
full.names=T)
# initialize a list to store datasets
datasets <- list()
# look for the specific groups and datasets
target_groups <- c("/projected_shap", "/raw", "/shap")
for (file in h5_files){
print(file)
h5_structure <- h5ls(file)
for (group in target_groups){
print(group)
# construct the full path to the dataset
full_key <- c(group%&%"/seq")
# read the dataset
data <- h5read(file, full_key)
# add or initialize the dataset in the list
if (!is.null(datasets[[full_key]])) {
datasets[[full_key]] <- datasets[[full_key]] + data
} else {
datasets[[full_key]] <- data
}
}
}
setwd("/Volumes/daniel/deeplearn_pred/github")
# list all .h5 files in the folder
h5_files <- list.files(getwd(),
pattern='^'%&%cond%&%'.*\\.'%&%dset%&%'_scores\\.h5$',
full.names=T)
# initialize a list to store datasets
datasets <- list()
setwd("/Volumes/daniel/deeplearn_pred/DIY/contribution_scores")
# list all .h5 files in the folder
h5_files <- list.files(getwd(),
pattern='^'%&%cond%&%'.*\\.'%&%dset%&%'_scores\\.h5$',
full.names=T)
# initialize a list to store datasets
datasets <- list()
# look for the specific groups and datasets
target_groups <- c("/projected_shap", "/raw", "/shap")
for (file in h5_files){
print(file)
h5_structure <- h5ls(file)
for (group in target_groups){
print(group)
# construct the full path to the dataset
full_key <- c(group%&%"/seq")
# read the dataset
data <- h5read(file, full_key)
# add or initialize the dataset in the list
if (!is.null(datasets[[full_key]])) {
datasets[[full_key]] <- datasets[[full_key]] + data
} else {
datasets[[full_key]] <- data
}
}
}
dim(datasets)
dim(datasets[[key]])
setwd("/Volumes/daniel/Asthma/05_QTL_mapping")
